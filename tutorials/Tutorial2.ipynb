{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the Jupyter Notebooks are available at https://github.com/neuro-ml/dpipe_tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorials on Deep Pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tutorials introduce the library called **Deep Pipe**, which is useful for medical image analysis, including preprocessing, data augmentation, performance validation and final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 2: Model initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the current tutorial we build a tensorflow model for image segmentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nmnt/media/home/shmulev/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# import deep pipe library\n",
    "# how to install: https://github.com/neuro-ml/deep_pipe/blob/master/README.md\n",
    "import dpipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from dpipe.dataset.brats import Brats2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# *The examples of the input arguments can be found at https://github.com/neuro-ml/deep_pipe/blob/master/config_examples/assets/data_source/.*\n",
    "\n",
    "# **Note:** We are using IITP machine with stored Brats dataset:\n",
    "# https://github.com/neuro-ml/deep_pipe/blob/master/config_examples/assets/data_source/iitp/brats.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset = Brats2017(data_path = \"/nmnt/t01-ssd/brats2017/train\", metadata_rpath = \"metadata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### I. Model Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model core is exactly neural net which will later be used for computing logits, losses and making predictions. A model core must have the method `build`, which builds the computational graph along with placeholders and operations and returns the sequence of input placeholders and output logits. *The source: https://github.com/neuro-ml/deep_pipe/blob/develop/dpipe/model_core/base.py*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can import DeepMedic net for image segmentation:\n",
    "*(see: https://github.com/neuro-ml/deep_pipe/blob/develop/dpipe/model_core/deepmedic_els.py)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dpipe.model_core\n",
    "from dpipe.model_core.deepmedic_els import DeepMedicEls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And initialize our model_core object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_core = DeepMedicEls(n_chans_in=4, n_chans_out=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It has the method `build`, which builds computational graph and returns: [x_det_ph, x_con_ph], logits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[x_det_ph, x_con_ph], logits = model_core.build(tf.placeholder('bool', name='is_training'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_det_ph, x_con_ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### II. TF Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we built our computational graph (we can compute logits!), we want to compute a certain loss, create a decision function, etc. Thus, we have to wrap our `model_core` net into another object called `model`, which attaches all the needed stuff (loss, optimizer, prediction function and so on)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dpipe.tf\n",
    "from dpipe.tf.model import TFModel, TFFrozenModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TFModel** is the interface for training a neural network model.\n",
    "\n",
    "Arguments:\n",
    "- model_core: ModelCore,\n",
    "- logits2pred: callable,\n",
    "- logits2loss: callable, \n",
    "- optimize: callable\n",
    "\n",
    "**TFFrozenModel** is the interface for making inference from already trained network.\n",
    "\n",
    "Arguments:\n",
    "- model_core: ModelCore,\n",
    "- logits2pred: callable,\n",
    "- restore_model_path\n",
    "\n",
    "*For more detailts: https://github.com/neuro-ml/deep_pipe/blob/develop/dpipe/tf/model.py*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize the models we have to pass several function (loss, prediction, optimizer). Let's import them from **dpipe.tf.utils**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dpipe.tf.utils import softmax_cross_entropy, softmax\n",
    "from dpipe.tf.utils import get_tf_optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create optimizer function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "optimize = partial(get_tf_optimizer, tf_optimizer_name='AdamOptimizer', beta1=0.899)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /nmnt/media/home/shmulev/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/training/python/training/training.py:412: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n"
     ]
    }
   ],
   "source": [
    "tf_model = TFModel(model_core, logits2pred=softmax, logits2loss=softmax_cross_entropy, optimize=optimize)\n",
    "#frozen_model = TFFrozenModel(model_core, logits2pred=softmax, restore_model_path='some_path_to_trained_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Methods of `TFModel` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `do_train_step(*train_inputs, lr)` - makes a training step for the given data, i.e. makes forward pass, computes the loss and make an weights update.\n",
    "- `do_val_step(*val_inputs)` - makes a validation step for the given data, i.e. computes the loss and predictions. \n",
    "- `do_inf_step(*inference_inputs)` - makes a inference step for the given data, i.e. makes predictions.\n",
    "- `save(path)` - saves the current session together with the trained model.\n",
    "- `restore(path)` - restores some session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```loss = tf_model.do_train_step(*some_inputs, lr=some_lr)\n",
    "y_pred, loss = tf_model.do_val_step(*some_inputs)\n",
    "y_pred = tf_model.do_inf_step(*some_inputs)```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
